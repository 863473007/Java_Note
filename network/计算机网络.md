1. PDU
    - PDU是指协议数据单元，用来描述通信协议。PDU是一个由二进制数据0和1组成的数据块，它由控制部分和数据部分组成：控制部分由若干个字段组成，就是通信双方遵循的规则和约定；数据部分一般为上一层次的协议数据单元，为了保证所传输的数据是有序的，并且是没有重复的，需要给传输的pdu设置序号

2. TCP/IP结构层次
    - 自底向上的层次依次是：网络接口层；IP层（互联网层）；TCP层（运输层）；应用层

3. TCP报文结构
    - ![shilitu](https://github.com/chuntaojun/Java_Note/blob/master/network/image/tcp-1.png)
    - 源端口、目的端口、序号和确认序号（TCP可靠传输的关键部分、一个字节一个序号）、首部长度、标志位（ACK、SYN、FIN）、滑动窗口（告知发送端接收端的缓存大小以此控制发送端的发送速率，从而达到流量控制）、检验和、紧急指针、选项和填充、数据
	- 对于一个只有一个IP的客户端来说，当它在应用层发起Connect操作时，它的源地址、目的地址、目的端口是确定的，而源端口是由操作系统指定(也可以事先通过bind来指定，稍后描述），操作系统将为了避免连接重用(相同的四元组），系统将保证对于相同的目的地址和端口将使用不同的本地端口，再依赖于net.ipv4.ip_local_port_range的限制，最多使用65535-1024个连接。如果采用主动bind的方式建立连接，出现了端口相同也将主动报错。
	- Nagle算法
		- 在数据传输过程中，通常会遇到一些小分组的传输（比如 41 bit的数据分组，除去TCP首部和IP首部真正传输的数据只有1 bit），像这种小分组多的话，在网络上传输就加大了造成网络拥塞的可能。为了提传输效率，所以提出了Nagle算法。这个算法要求一个TCP连接最多只能有一个未被确认的未完成的小分组，在该分组到达之前不能发送其他的小分组。然后，TCP会收集这些小分组，并在确认到来时以一个分组的方式发送出去，这样就可以有效的减少了小分组。 在一些实时性要求比较高的场景下，采用了Nagle算法会让用户感觉到时延，所以我们可以选择关闭Nagle算法，Socket API 可以用 TCP_NODELAY 选项来关闭，nginx上的 tcp_nodely也是采用的这个系统调用。
	- TCP滑动窗口
        - ![shilitu](https://github.com/chuntaojun/Java_Note/blob/master/network/image/tcp-2.png)
        - TCP在双方数据传输的过程中，都会维护一个窗口，它代表了我还可以接受的数据的大小。如果接收方窗口大小为0，发送方就会停止发送。之所以叫滑动窗口（Sliding Window）是因为它是动态可变的，不是固定的（张开、合拢、收缩）。它保证了数据的可靠传递、它确保数据按顺序传递、并且它强制发送者之间的流量控制
    - TCP拥塞控制
		- 慢启动和拥塞避免
            - 慢启动和拥塞避免算法必须被TCP发送端用来控制正在向网络输送的数据量。为了实现这些算法，必须向TCP每连接状态加入两个参量。拥塞窗口（cwnd）是对发送端收到确认（ACK）之前能向网络传送的最大数据量的一个发送端限制，接收端通知窗口（rwnd）是对未完成数据量的接收端限制。cwnd和rwnd的最小值决定了数据传送。 另一个状态参量，慢启动阀值（ssthresh），被用来确定是用慢启动还是用拥塞避免算法来控制数据传送。 在不清楚环境的情况下向网络传送数据，要求TCP缓慢地探测网络以确定可用流量，避免突然传送大量数据而使网络拥塞。在开始慢启动时cwnd为1，每收到一个用于确认新数据的ACK至多增加SMSS（SENDER MAXIMUM SEGMENT SIZE）字节。 慢启动算法在cwnd&lt;ssthresh时使用，拥塞避免算法在cwnd&gt;ssthresh时使用。当cwnd和ssthresh相等时，发送端既可以使用慢启动也可以使用拥塞避免。 当拥塞发生时，ssthresh被设置为当前窗口大小的一半（cwnd和接收方通告窗口大小的最小值，但最少为2个报文段）。如果是超时重传，cwnd被设置为1个报文段（这就是慢启动，其实慢启动也不慢，它是指数性增长，只是它的起始比较低）当达到ssthresh时，进入拥塞避免算法（拥塞避免是线性增长）。
            - ![shilitu](https://github.com/chuntaojun/Java_Note/blob/master/network/image/tcp-3.png)
    - 快速重传和快速恢复
        - 当接收端收到一个顺序混乱的数据，它应该立刻回复一个重复的ACK。这个ACK的目的是通知发送端收到了一个顺序紊乱的数据段，以及期望的序列号。发送端收到这个重复的ACK可能有多种原因，可能丢失或者是网络对数据重新排序等。在收到三个重复ACK之后（包含第一次收到的一共四个同样的ACK），TCP不等重传定时器超时就重传看起来已经丢失（可能数据绕路并没有丢失）的数据段。因为这个在网络上并没有超时重传那么恶劣，所以不会进入慢启动，而进入快速恢复。快速恢复首先会把ssthresh减半(一般还会四舍五入到数据段的倍数)，然后cwnd=ssthresh+收到重复ACK报文段累计的大小。
        - ![shilitu](https://github.com/chuntaojun/Java_Note/blob/master/network/image/tcp-4.png)
    
4. 网络服务的服务原语
	- 服务原语由三部分组成：原语名；原语类型；预案语参数
		- 原语类型
		    - 请求：发送方希望得到某些服务
			- 指示：接受方得知某个事件发生
			- 响应：接收方对某个事件的应答
			- 证实：发送方得知请求的结果
		- 书写时的要求：：原语类型用小写字母表示；原语名用大写字母表示；原语参数用圆括号括起

5. 为什么TCP连接需要三次握手，而断开需要四次挥手
	- TCP的链接建立是通过文件描述符完成的，通过创建套接字获得一个fd（fd的数量决定了服务端进程所能建立连接的数量）
	- TCP三次握手中，Client发送syn，server收到后会syn_ack，接着client再回ack，这时client便完成了connect调用，进入estab状态
	- 三次握手的原因
		- 如果两次握手的话，容易造成服务器创建连接造成长时间连接无用，创建无用过的连接，导致资源浪费
		- 两方建立通信只要三步就够了（确定各自的发送、接收功能完好）
	- 三次握手的过程
		- 当 client 通过 connect 向 server 发出 SYN 包时，client 会维护一个 socket 等待队列，而 server 会维护一个 SYN 队列
		- 进入半链接的状态，如果 socket 等待队列满了，server 则会丢弃，而 client 也会由此返回 connection time out；只要是 client 没有收到 SYN+ACK，3s 之后，client 会再次发送，如果依然没有收到，9s 之后会继续发送
		- 当 server 收到 client 的 SYN 包后，会返回 SYN, ACK 的包加以确认，client 的 TCP 协议栈会唤醒 socket 等待队列，发出 connect 调用
		- client 返回 ACK 的包后，server 会进入一个新的叫 accept 的队列，该队列的长度为 min(backlog, somaxconn)，默认情况下，somaxconn 的值为 128，表示最多有 129 的 ESTAB 的连接等待 accept()，而 backlog 的值则由 int listen(int sockfd, int backlog) 中的第二个参数指定
		- 当 accept 队列满了之后，即使 client 继续向 server 发送 ACK 的包，也会不被响应，此时，server 通过 /proc/sys/net/ipv4/tcp_abort_on_overflow 来决定如何返回，0 表示直接丢丢弃该 ACK，1 表示发送 RST 通知 client；相应的，client 则会分别返回 read timeout 或者 connection reset by peer
        - ![shilitu](https://github.com/chuntaojun/Java_Note/blob/master/network/image/tcp-5.png)
    - 四次挥手的原因
        - TCP连接的释放一共需要四步，因此称为『四次挥手』。 
		- 我们知道，TCP连接是双向的，因此在四次挥手中，前两次挥手用于断开一个方向的连接，后两次挥手用于断开另一方向的连接。
		    - 第一次挥手 
			    - 若A认为数据发送完成，则它需要向B发送连接释放请求。该请求只有报文头，头中携带的主要参数为
			    - FIN=1，seq=u。此时，A将进入FIN-WAIT-1状态
                    - PS1：FIN=1表示该报文段是一个连接释放请求。
                    - PS2：seq=u，u-1是A向B发送的最后一个字节的序号。
			- 第二次挥手 
			    - B收到连接释放请求后，会通知相应的应用程序，告诉它A向B这个方向的连接已经释放。此时B进入CLOSE-WAIT状态，并向A发送连接释放的应答，其报文头包含： 
			        - ACK=1，seq=v，ack=u+1。
				        - PS1：ACK=1：除TCP连接请求报文段以外，TCP通信过程中所有数据报的ACK都为1，表示应答。
				        - PS2：seq=v，v-1是B向A发送的最后一个字节的序号。
				        - PS3：ack=u+1表示希望收到从第u+1个字节开始的报文段，并且已经成功接收了前u个字节。
			        - A收到该应答，进入FIN-WAIT-2状态，等待B发送连接释放请求。
			        - 第二次挥手完成后，A到B方向的连接已经释放，B不会再接收数据，A也不会再发送数据。但B到A方向的连接仍然存在，B可以继续向A发送数据。
			            - 这时，B会马上进入CLOSE_WAIT状态，表示在等待关闭，通知应用发送剩余数据
			- 第三次挥手
			    - 当B向A发完所有数据后，向A发送连接释放请求，请求头：FIN=1，ACK=1，seq=w，ack=u+1。B便进入LAST-ACK状态。
			- 第四次挥手 
			    - A收到释放请求后，向B发送确认应答，此时A进入TIME-WAIT状态。该状态会持续2MSL时间，若该时间段内没有B的重发请求的话，就进入CLOSED状态，撤销TCB。当B收到确认应答后，也便进入CLOSED状态，撤销TCB。
			    - 这时，A会马上进入TIME_WAIT状态
			        - 为什么A要先进入TIME-WAIT状态，等待2MSL时间后才进入CLOSED状态？ 
				        - 为了保证B能收到A的确认应答。 
				        - 若A发完确认应答后直接进入CLOSED状态，那么如果该应答丢失，B等待超时后就会重新发送连接释放请求，但此时A已经关闭了，不会作出任何响应，因此B永远无法正常关闭。
				        - 防止已失效的请求数据包与正常链接的请求数据包混淆
	- TCP连接关闭时TIME_WAIT存在的理由
		- 可靠的实现TCP全双工连接的终止
		- 允许老的重复分节在网络中消逝
			- 创建一个新连接时，来自该连接先前化身的老的重复分组都已经在网络中消逝了
    
7. 什么是session
	- Session-id存在cookie中传到客户端，以此来标识具体是哪一位用户
	- 如果客户端浏览器禁用cookie，此时服务器端的session随之失效（无法根据session-id去判断该请求所对应的用户）；但是可以通过url重定向，将session-id附带在url的get参数中（存在篡改以及被获取的危险）
	- 生命周期：请求端与web应用进行一次会话的过程
	
8. Http协议
	- GET和POST请求的区别
		- 请求是否是幂等性的：GET和POST最大的区别主要是GET请求是幂等性的，POST请求不是
		- 数据传输的方式存在不同：GET使用URL或Cookie传参，而POST将数据放在BODY中，这个是因为HTTP协议用法的约定。并非它们的本身区别
		- 提交的数据长度不同：GET方式提交的数据有长度限制，则POST的数据则可以非常大”，这个是因为它们使用的操作系统和浏览器设置的不同引起的区别。也不是GET和POST本身的区别
		-  提交数据的安全性：POST比GET安全，因为数据在地址栏上不可见”，这个说法没毛病，但依然不是GET和POST本身的区别
	- 以前的Http1.1存在的问题
		- TCP连接数目存在限制（一般浏览器对于同一个域名，最多创建6~8个TCP连接），为了解决此问题，出现了域名分片（资源分域，不同的资源放在不同的域名下），但是存在一些问题：TCP连接本身需要DNS查询、三步握手、慢启动以及占用额外的CPU和内存，同时也容易造成网络拥挤等问题
        - 每一个TCP连接同时只可以处理一个请求-响应，浏览器按照FIFO的原则处理请求，如果上一个请求未解决，那么接下来的请求都会被阻塞（HTTP管线化技术：将多个HTTP请求整批提交，而在发送过程中不需先等待服务器的回应），但是服务端必须按照客户端的请求顺序恢复请求，因此仍然存在队头阻塞问题；同时该技术必须透过永久连线完成，并且只有GET、HEAD可以要求进行管线化，非幂等性的方法不会被管线化
            - HTTP管线化技术示例图
                - ![shilitu](https://github.com/chuntaojun/Java_Note/blob/master/network/image/tcp-6.png)
        - Header内容多，且每次请求时Header不会变化太多，没有相应的压缩传输优化方案
		- 为了减少请求数，需要做合并文件、资源内联等优化工作，但是会造成请求内容变大导致传输变高得到问题，并且资源内联无法有效的使用缓存机制
    - Http2
        - 允许同时通过单一的http/2链接发起多重的请求-响应消息（多流并行）、每个来源一个连接（对于一个域名创建一个TCP连接即可）
        - ![shilitu](https://github.com/chuntaojun/Java_Note/blob/master/network/image/tcp-7.png)
        - 服务端推送（Server Push）
			- 浏览器发送一个请求，服务器主动向浏览器推送与这个请求相关的资源，浏览器无需发起后续请求
			- 优势
				- 客户端可以缓存推送的资源
				- 客户端可以拒绝推送过来的资源
				- 推送资源可以由不同页面共享
				- 服务器可以按照优先级推送资源
		- 允许为请求设置优先级，让更重要的请求更快速地完成
			- 允许每个数据流都有一个关联的权重和依赖关系。
			- 每个数据流与其他数据流之间可以存在显式依赖关系。
			- 数据流依赖关系和权重的组合让客户端可以构建和传递“优先级树”，表明它倾向于如何接收响应；反过来，服务器可以使用此信息通过控制 CPU、内存和其他资源的分配设定数据流处理的优先级，在资源数据可用之后，带宽分配可以确保将高优先级响应以最优方式传输至客户端
			- 不能保证特定的处理或传输顺序，客户端无法强制服务器通过数据流优先级以特定顺序处理数据流
		- 将http协议通信的基本单位缩小为了一个一个的帧，帧对应着逻辑流里的信息，并行的在同一个tcp连接上双向交换信息
		- 二进制分帧：http首部信息放入head-frame中，请求体放入data-frame中
		- 所有通信都在一个 TCP 连接上完成，此连接可以承载任意数量的双向数据流
		- 每个数据流都有一个唯一的标识符和可选的优先级信息，用于承载双向消息
		- 每条消息都是一条逻辑 HTTP 消息（例如请求或响应），包含一个或多个帧
		- 帧是最小的通信单位，承载着特定类型的数据，例如 HTTP 标头、消息负载等等。 来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装
		- 三个概念
			- 数据流：已建立的连接内的双向字节流，可以承载一条或多条消息。
			- 消息：与逻辑请求或响应消息对应的完整的一系列帧。
            - 帧：HTTP/2 通信的最小单位，每个帧都包含帧头，至少也会标识出当前帧所属的数据流



