1. Java
    - Java事务分为哪一些
        - Java事务三种类型:JDBC事务、JTA（Java Transaction API）事务、容器事务
        - JDBC 事务是用 Connection 对象控制的。JDBC Connection 接口（ java.sql.Connection ）提供了两种事务模式：自动提交和手工提交。 java.sql.Connection 提供了控制事务的方法

    - 为什么Java自带的反射机制，只针对于接口工作
        - 通过Java的动态代理实现的代理类，其都会继承一个Proxy的类，由于Java的单继承机制，因此只能代理接口

    - 对象序列化时，如何兼容以前的对象为实现序列化接口？
        - 使用Externalization接口，对以前未实现序列化的对象采用Json方式转为String，然后序列化String
    
    - 当Java程序占用CPU高达百分之百时，如何定位错误的原因（基本上为线程的原因）
        - 获取到对应Java程序的PID信息
        - 使用命令：ps -mp &lt;PID&gt; thread，tid，time定位出CPU占用率最高的线程信息（或者使用 top -H -p &lt;PID&gt;进行显示，可以直接看到CPU使用率高的线程信息）
        - 使用print “%x\n” &lt;tid&gt;得到线程的16进制数字表示
        - 使用jstack进行当前线程信息dump到文件当中，然后在导出的文件当中进行搜索对应的线程&lt;tid&gt;，进行错误定位

    - Java集合中的fail-fast机制
        - 两个重要参数：expectModcount 以及modcount（modCount 用来记录结构发生变化的次数）

    - 我在试图分配一个 100M bytes 大数组的时候发生了 OOME，但是 GC 日志显示，明明堆上还有远不止 100M 的空间， 你觉得可能问题的原因是什么
        - 当前新生代 or 老年代内存的大小无法分配一个100Mbytes大小的数组了
        - 堆内存大小够，但是找不到连续的空间存放这个100M bytes的数组

    - 为什么要用Class.forName加载驱动
        - Class.forName加载驱动能够执行类的static静态代码块，第三方数据库驱动会在静态代码库向jdbc注册自己的驱动对象
        - 避免第三方驱动的类侵入代码，用字符串代替类，避免耦合
        - 为了兼容旧版本的JDK以及老旧的数据库驱动架包

    - Java中jre\bin目录和jdk\bin目录下的工具功能介绍
        - 具体url地址：https://blog.csdn.net/eclipse_yin/article/details/51051096

    - Java内存溢出的常见问题
        - 堆溢出：强引用无法回收
        - 直接内存溢出：NIO的buffer是使用直接内存的（合理的执行显示gc、设置最大直接内存大小）
        - 永久区溢出

    - Java逃逸分析
        - 逃逸分析(Escape Analysis)是目前Java虚拟机中比较前沿的优化技术。这是一种可以有效减少Java 程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法。通过逃逸分析，Java Hotspot编译器能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上
        - 将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是栈分配的候选，而不是堆分配
        
    - 什么是方法重载，什么是方法重写（方法覆盖，子类实现父类的方法后，父类方法被隐藏）
        - 方法重载是针对于同一个方法名，但是有不同的入参（涉及方法的签名，注意，返回值不参与方法签名），并且方法重载是发生在同一个类中的
        - 重写则是发生在父类与子类中，子类继承父类后重写父类的方法

    - JVM
        - CMS GC发生concurrent mode failure时，为什么使用单线程的full GC
            - 有可能是由于promotion failed引起的（Young GC 时由于对象需要从新生代提升到老年代，但老年代空间由于各种原因存放不下这些对象，触发promotion failed，引发一次Full GC对老年代和永久代进行回收，因此是会暂停业务线程引起停顿的）
            - 当minor GC进行时，1）旧生代所剩下的空间小于Eden区域+From区域的空间；2）在CMS执行老年代的回收时有业务线程试图将大的对象放入老年代，导致CMS在老年代的回收慢于业务对象对老年代内存的分配（Minor GC后， Survivor空间容纳不了剩余对象，将要放入老年代，老年代有碎片或者不能容纳这些对象，就产生了concurrent mode failure, 然后进行stop-the-world的Serial Old收集器）

    - CGLib原理
        - 早期处理（javaagent）
		    - 在加载class文件之前做拦截（premain，虽然说对业务透明，无侵入性，但是因为只在class文件加载之前生效，一旦class加载完后，就无法工作了，只能重新创建classloader）
		- 字节码操作工具ASM
			- 直接产生二进制的class文件
			- 三大核心类（classreader、classvisitor，classwriter）
			- 在JDK的反射功能中，也是用了ASM（当反射调用的次数达到某一个设定的阈值后，会从反射调用转为采用字节码框架生成一个动态类，进行优化，因为动态类的创建相比JDK原生反射要来得慢，但是在最终的function调用上是比JDK原生要快的）
        - 根据传入的Class对象，逆向生成对应的字节码数据，然后通过类加载器，将生成的字节码数据转载入类加载器中，得到一个新的Class对象（其本质是继承传入的Class，生成一个子类，因此CGLib动态代理无法代理被final修饰的方法）
        - ![cglib-原理](https://github.com/chuntaojun/Java_Note/blob/master/faq/image/0BC42224-F23C-C44D-B314-EF32EC02416F.png.png)

2. 计算机网络
    - 为什么要使用Http连接池
        - 降低延迟：如果不采用连接池，每次连接发起Http请求的时候都会重新建立TCP连接(经历3次握手)，用完就会关闭连接(4次挥手)，如果采用连接池则减少了这部分时间损耗，别小看这几次握手，本人经过测试发现，基本上3倍的时间延迟
    - 支持更大的并发：如果不采用连接池，每次连接都会打开一个端口，在大并发的情况下系统的端口资源很快就会被用完，导致无法建立新的连接
3. 消息队列
    - 订单超时状态的变更
        - reids的过期键值消息通知：存在消息丢失的情况，如果消息订阅者（or 监听者）因为某些原因而无法收到消息的话，那么这个消息就会丢失，从而导致任务无法通知到系统中
		- 任务框架quartz：性能不强，非常依赖数据库的性能，在面对大量的超时订单的情况下，由于数据库的性能瓶颈在那，加上如果大量任务堆积，极大的影响这个系统的性能（数据库的查询+数据数据的更新都是耗时的操作）
		- 延时消息队列：目前是比较好的解决方案，其实redisd的过期键值通知系统就类似于这个消息延时队列系统，但是美中不足的问题是由于缺乏ACK确认机制，容易造成消息丢失的问题；而消息延时队列其实可以认为是一个优先队列，最接近当前时间的事件会被推出队列，因此无需轮询整个订单系统，提升了效率；第二，确保一个消息只会被处理一次；第三，时效性强，不需要像任务框架一样，通过定期的轮询操作查出当前最应该被处理的任务（这种轮询的处理操作容易带来时间的不准确性以及任务的时效性得不到保证）
            - 需要考虑的点：如果数据量少，那么直接采用JVM内存消息队列即可，但是如果单个消息对象大、消息数据量多且延迟时间长，那么可能导致大量的消息暂时积压在了队列中，亦有可能导致OOM异常的发生，这个时候就需要去考虑数据持久化问题
    
    - 引入消息队列的优劣
		- 好处
			- 系统解耦，消息生产者只需要向消息队列中放入消息（最多创建几个topic，根据topic放入消息）
			- 无需关心谁去消费消息，无需保证消息是否被消费，无需关心消费者是否收到了消息
			- 接口调用异步化：有效的优化了系统接口的耗时（无需等待耗时且与业务无关的接口）
			- 流量削峰（大量请求直接命中MySQL，大量的SQL语句被执行，导致数据库被压崩了）
			    - 将用户请求打到MQ上，每秒处理的请求可以根据消费者的处理能力执行拉取需要的数据，高峰期过后仍然能够按原有的处理速度高效处理请求数据
				- 但是可能会造成用户响应的缓慢
		- 坏处
			- 增加系统的维护难度、系统复杂性提升（添加了额外的组件）
			- 增加了系统的不稳定性（一旦消息队列系统崩溃，整个系统直接宕）——消息队列集群  
            - 消息的重复处理解决（幂等性问题）、消息丢失问题的解决、消息顺序的混乱、消息 积压的问题、事务一致性

    - 消息出现重复怎么处理（如何解决重复消息问题）
		- 为什么消息出现重复消费
			- 客户端与服务端都可能导致此问题的出现
			- Kafka（消息消费偏移量上报机制）
				- kafka内部存在一个offset机制，用于client端主动上报自己的消息消费位置，如果消费者未来得及上报自己的offset，那么可能导致下次消费者启动时导致消息重复消费（对于offset，并不是说消费者消费一条立马上报一条（太耗费时间以及资源了）；但是可以自行设置offset提交）
			- 幂等性实现（GET请求、PUT请求）
				- 消费一条数据时，往某个地方插入数据消费记录（后面来的消息根据此存储进行判断）
		- 消息丢失问题（消息传输的可靠性）
			- RabbitMQ
				- MQ自己消息丢失（系统）
					- 消息队列的事务功能（rabbitmq）
					- 采用ACK确认机制，开发时为每条消息赋予唯一ID，通过ACK机制实现消息失败重试（回调机制，错误调用回调函数，可用于生产者，不会阻塞生产者的消息产生）
					- 消息队列宕机可能导致丢失数据：数据的持久化实现，可以结合confirm机制，只有消息被持久化了才会通知生产者（但是又会带来吞吐量下降的问题）
				- 消息消费时丢失（人为）
					- 开启了AutoAck机制，导致消费者消费到了消息但是还未来得及处理完消息就挂了，导致数据丢失（MQ认为你消费完了，自动下发下一条消息）
			- Kafka
				- 消息丢失
                    - 消费者获取到了消息，提交offset，kafka认为消费成功，而此时消费者挂了，导致消息未处理完
                        - ![示例图](https://github.com/chuntaojun/Java_Note/blob/master/faq/image/BF1875F9-291B-0C47-B301-A40E6543487C.png)
                    - leader接收到消息后，尚未完成数据广播到follower时，自己宕机了，导致新的leader没有旧leader的接收到的新的数据，导致数据丢失
                - 生产环境必须设置的三个参数（确保消息不丢失）
					- Replicatioin.factor：每个topic设置该参数，确保每个partition必须至少两个副本
					- Min.insync.replicas：要求一个leader至少感知到一个follower在与自己保持联系
					- Acks=all：要求每条数据必须写入所有的replica后才可认为写入成功
                    - Retrise=max：无限重试消息发送
        - 消息顺序消费问题
            - 几个发生消息顺序错误场景
				- rabbitmq：一个queue多个consumer
				- kafka：一个topic，一个paration，consumer内部多个线程，也会导致消息顺序错乱
			- 解决
				- 一定要顺序性的消息确保路由到同一个消息队列中，确保一个消息队列只被一个消费者消费（针对于rabbitmq）
				- 消费者内部在设计多个内存队列，消费者根据消息的key进行hash分发（相当于一个内存级别的rabbitmq），每个线程消费各自订阅的队列，即可保证消息消费的顺序性
		- 消息积压问题
			- 方案一：紧急扩容，短期内扩大消费者数量，创建一个新的topic（包含大量分区）
				- 原有的消费者更改消息消费代码，将消费的消息快速写入新创建的topic中，同时在创建新的消费者去消费新的topic（数量与分区数量一致），然后进行数据落库操作，该topic消费往后，在将原有的消费者消息消费代码更改回原先消费操作
		- 消息延时并且消息过期怎么办

4. Josn Web Token
	- 组成
		- 由三部分组成，头部、载荷与签名依顺序用点号（"."）链接而成：1.header，2.payload，3.signature
		- 头部：说明类型和使用的算法
		- 载荷：存放有效信息
			- 标准中注册的声明，公共声明，私有声明
			- 标准中的注册声明：
				- iss: jwt签发者
				- sub: jwt所面向的用户
				- aud: 接收jwt的一方
				- exp: jwt的过期时间，这个过期时间必须要大于签发时间
				- nbf: 定义在什么时间之前，该jwt都是不可用的.
				- iat: jwt的签发时间
				- jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。
			- 签名：这个部分需要base64加密后的header和base64加密后的payload使用.连接组成的字符串，然后通过header中声明的加密方式进行加盐secret组合加密，然后就构成了jwt的第三部分，用于jwt的签发与验证

5. Nginx
	- 为什么nginx适合静态资源代理
		- 静态资源的特性：静态资源的更新频率不高，因此基本上可以看作是不改变的，而nginx使用proxy_cache将用户请求缓存到本地的一个目录，下一次相同的请求可以直接调用缓存文件
		- IO密集型服务的处理是nginx的强项

6. Redis
	- redis的使用场景
	- 缓存
		- Redis缓存雪崩
			- 缓存的失效时间同时达到，导致大量数据查询无法从缓存中获取，全部命中数据库
			- 解决方案
				- 过期时间+随机的时间，尽可能的将过期时间错开、互斥锁排队
				- 缓存备份，同时创建缓存A与缓存B，当A缓存数据过期时查询缓存B，同时更新缓存A、B
				- Redis cluster模式，集群确保redis高可用
				- 本地ehcache缓存+hystrix限流 & 降级
		- Redis缓存击穿（恶意攻击问题）
			- 请求无法击中缓存数据，过多的请求访问了缓存中不存在的数据，造成大量的查询命中数据库
			- 解决方案
				- 互斥锁排队（效率最低）
				- BloomFilter过滤器（存在一定的误差，但是效率高、适用于数据相对固定实时性低，如果说bloomfilter说不存在则一定不存在）
				- 缓存空对象（耗费过多的缓存空间，数据不一致问题、适用于数据频繁变化实时性高）
		- 缓存热点Key
	- Redis作为消息队列为什么不能保证 100% 的可靠性
		- 缺乏ACK确认机制，可能导致消息漏收或者消息重复处理（消息幂等性的处理）
		- 如果redis被订阅了消息但是又没有相应的消费者处理消息，此时redis不阻止消息的发送，而是继续发送消息，这个时候就会发生消息丢失的问题
	- redis单线程（此处的单线程仅仅指网络模块）如此快的原因（非阻塞IO以及存内存操作）
		- 网络模块单线程能够避免多线程的上下文切换的开销
		- redis支持服务器端操作，省去数据来回网络开销（相比memcached），原生支持集群模式
		- 所有命令都是在内存当中，所有的运算级别都是内存级别的运算
		- 懒惰删除
			- 虽然redis的del指令的执行速度比较快，但是如果删除的key是一个非常大的对象，那么删除操作就会造成单线程卡顿
				- 注意，并不是所有的key都会延迟删除，如果key很小，那么直接删除就好
			- 采用懒删除方案，在redis4.0版本加入unlink指令，对删除进行懒处理，丢给后台线程来异步回收线程；并且并不会导致多个线程同时并发修改数据结构的情况出现（使用unlink指令后，该key就无法被其他线程访问到）
		- 处理并发客户端的链接，采用多路复用（select系列的事件轮询api，而不是阻塞IO模型，与netty的模型基本相同NIO）
		- 每个客户端套接字都关联到一个指令队列，客户端的指令通过队列来排队进行顺序处理，先到先服务；同时redis也会为每个客户端套接字关联一个响应队列，redis服务器通过响应队列来将指令的返回结果回复给客户端，如果队列为空，则不需要获取写事件
		- 定时任务：定时任务会记录在一个称为最小堆的数据结构中，这个堆中，最快要执行的任务派在堆的最上方，最快要执行的任务还需要的时间记录下来，作为select系统调用的timeout参数（因为redis知道未来timeout时间内，没有其他定时任务需要处理）
		- 线程模型
			- 文件事件处理器：基于reactor模式开发网络事件处理器，采用I/O多路复用机制；事件处理器是单线程模式运行的，但是可以通过I/O多路复用机制监听多个socket（只负责监听——压队列，将具体的处理转交给其他线程）
			- 包括多个socket、I/O多路复用程序，文件事件分派器，事件处理器
			- 每个socket产生的不同文件事件，I/O多路复用器会将程序放入队列中排队，每次从队列中取出socket给事件分派器，事件分派器根据事件类型将事件分给对应的处理器
				- 会创建一个与客户端对应的socket
			- ![示例图](https://github.com/chuntaojun/Java_Note/blob/master/faq/image/C8D7ED2B-9E2C-C740-AB83-20DFAE8BCA11.png)
		- 多路复用（事件轮询API，系统给出的是可读可写事件，同时提供等待超时参数）
			- ![示例图](https://github.com/chuntaojun/Java_Note/blob/master/faq/image/29E20704-4BDE-EC4F-9294-15F6FC46C3DA.png)
	- 如何使用其他命令代替redis的keys命令（keys命令是全表扫描，对于redis这个单线程的程序来说，会存在阻塞的情况）
		- 使用scan命令，scan命令是通过游标分步进行的，不会阻塞线程；提供limit参数，用于限定服务器单次遍历槽位数量；也提供模式匹配功能；服务器端不需要为游标保存状态，游标整数会返回给客户端；返回的结果可能会有重复，需要客户端去重；遍历过程中数据有修改，改动后的数据能不能遍历到是不确定的；返回的结果为空不代表遍历结束，而是要看返回的游标整数是否为零
	- redis的事务为什么不能支持回滚
		- redis执行失败只有一个原因——redis命令错误，而这个错误是由于编程错误造成的，因此错误应该在开发过程中被发现
	- redis集群模式中，master如何知道slave是否是第一次链接（offset进行判断）
		- 从redis 2.8开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份（类似MySQL的checkpoint机制，提升性能）；master-node会在内存中创建一个backlog，master和slave都会保存一个replica-offset还有一个master-id，offset就是保存在backlog中的。如果master和slave网络连接断掉了，slave会让master从上次的replica offset开始继续复制，但是如果没有找到对应的offset，那么就会执行一次resynchronization
		- lave会上报自己的offset给master，同时master也会保存每个slave的offset，因此master以及slave知道各自的offset，才知道互相之间数据不一致的情况
		- slave会存储master的run-id，run-id不同就执行全量复制；如果执行增量复制时，slave会在psync中带上offset，master就根据这个offset从backlog查找数据
			- Run-id是什么：主库的 run-id 是在主库进程启动之后生成的唯一标识（由进程id加上随机数组成）
		- 主从节点之间会通过heartbeat进行判断链路是否存活
		- master宕机后执行主备切换
			- 使用哨兵节点，哨兵节点会去监听master node，当监听到master node宕机时，会去选择一个slave node，将它提升为master node
			- redis主从同步采用异步复制，意味着当主节点挂掉时，从节点可能没有收到全部的同步消息，这部分未同步的消息就丢失了，并且sentinel无法保证消息完全不丢失
			- 宕机存在两种情况：sdown（主观宕机）以及odown（客观宕机，大部分哨兵认为master宕机后，主观宕机变为客观宕机）
			- 哨兵之间的发现是通过redis的pub/sub，向特定的channel发送消息 
				- configuration传播：每一次的主备切换，都会从新的master得到一个configuration epoch，就是一个version号，每次切换的version都是唯一的；哨兵完成切换之后，会在自己本地更新生成最新的master配置，然后同步给其他的哨兵
				- 哨兵是通过version版本号的大小来更新自己的master配置的
			- 存在对slave自动纠正功能（连接到正确的master中；slave要成为候选人时，确保slave在复制现有master的数据）
			- slave->master的选举算法
				- slave跟master断开链接的时长，slave的优先级、复制offset、run-id
				- 如果与master断开连接的时间超过down-after-millisecond的10倍，再加上master宕机时长，slave会被认为不适合选举为master
				- slave排序：slave优先级（priority越小优先级越高 ）、offset（越靠后优先级越高）、run-id（越小优先级越高）
		- redis主从情况下，如何解决数据延迟问题（redis的主从目前无法保证强一致性）
			- 经过一个确定的时间窗口后确保数据一致性
	- 如何解决redis异步复制或者脑裂导致的数据丢失
		- 出现原因：master与slave的数据复制是异步的
			- 由于网络问题，master与slave失去连接，此时哨兵选举出了一个新的master；而此时client未来得及获取新的master信息，依旧向旧的master写入信息，当旧master重新接入集群中时，被降级为slave，从新的master中获取数据从而造成数据丢失
		- 解决方案：设置min-slaves-to-write以及min-slaves-max-lag，即要求最少有n个slave，数据复制以及同步的延迟不超过m秒
	- 单机redis面对海量数据的瓶颈（redis-cluster）
		- 多master，横向扩容（如何确定数据查询落在哪个master中？）——redis-cluster中的hash slot算法
			- Hash solt算法
				- 有固定的16384个hash slot，对每个key计算CRC16，然后取模计算获取对应key的hash slot
				- 增加或减少master，只需要将其他的master上的slot进行迁移即可
				- 任何一台机器宕机，不影响查找，key找的是hash slot而不是机器；会将宕机的master的所拥有的hash slot均匀的分给其他的master中
	- 缓存与数据库双写时数据不一致的问题
		- 典型模式：cache aside pattern（读的时候先读缓存，缓存没有读数据库，然后将数据放入缓存；更新时，先删除缓存，然后在更新数据库，这里采用了lazy思想）
			- 何不进行更新缓存而是删除缓存？缓存的数据可能是涉及复杂的表连接查询，缓存更新代价高；缓存是否会被频繁读取到？如果没有，频繁更新缓存反而浪费性能，不如等到用的时候在进行计算（lazy计算思想 ）
			- 先删除缓存在删除DB与先删除DB在删除缓存的区别
				- 先缓存在DB：容易引发脏数据的问题（如果还在update的时候请求进来结果拉取老的数据）
				- 先DB在缓存：容易引发数据不一致的问题（还在update的时候，结果下一个update请求从缓存中获取老的数据信息去update）
		- 数据库与缓存操作异步串行化（任务队列）
			- 为什么？
				- 每个工作线程串行拿到对应的操作，然后一条一条的执行；这样的话，一个数据变更的操作，先执行，删除缓存，然后再去更新数据库，但是还没完成更新；此时如果一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成，这里有一个优化点，一个队列中，其实多个更新缓存请求串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可
			- 依据数据标示进行任务路由操作，发送至JVM内部的队列中
			- 可以为读请求进行hang住操作，延迟读请求的操作，不是所有读请求都需要压入队列中，如果队列中的更新请求后面已经跟了一个读操作，直接将后面的读请求操作进行hang住一段时间
			- 缺点：可能导致队列中存在大量的更新操作，导致读请求发生大量超时（部署多个服务实例，减轻更新压力）；如果路由到了不同的服务实例上怎么办（又再次回到了最开始的问题—读写异步）
				- 如何解决路由问题：自行实现请求hash到某个机器
	- redis高并发下的竞争问题
		- 分布式锁（确保同一时间只有一个实例能够操作数据）+ 数据版本时间戳比对
		- Redis的CAS方案

7. MySQL
	- 数据库三大范式
		- 1NF：关系中的每个属性无法再分
		- 2NF：属性完全依赖于主键（消除部分子函数依赖）
		- 3NF：属性不依赖于其他非主属性（消除传递性依赖）
	- 单列索引无法储null值，复合索引无法储全为null的值
		- 联合索引失效问题
			- MySQL会从左开始一直向右匹配直到遇到范围查询（>,<,BETWEEN,LIKE）就停止匹配
			- 对于复合索引：Mysql从左到右的使用索引中的字段，一个查询可以只使用索引中的一部份，但只能是最左侧部分。例如索引是key index （a,b,c）。 可以支持a | a,b| a,b,c 3种组合进行查找，但不支持 b,c进行查找 .当最左侧字段是常量引用时，索引就十分有效
			- 所以说创建复合索引时，应该仔细考虑列的顺序。对索引中的所有列执行搜索或仅对前几列执行搜索时，复合索引非常有用；仅对后面的任意列执行搜索时，复合索引则没有用处
				- select * from myTest  where a=3 and b=5 and c=4;   ----  abc顺序
			abc三个索引都在where条件里面用到了，而且都发挥了作用
				- select * from myTest  where  c=4 and b=6 and a=3;
			where里面的条件顺序在查询之前会被mysql自动优化，效果跟上一句一样
				- select * from myTest  where a=3 and c=7;
			a用到索引，b没有用，所以c是没有用到索引效果的
				- select * from myTest  where a=3 and b>7 and c=3;     ---- b范围值，断点，阻塞了c的索引
			a用到了，b也用到了，c没有用到，这个地方b是范围值，也算断点，只不过自身用到了索引
				- select * from myTest  where b=3 and c=4;   --- 联合索引必须按照顺序使用，并且需要全部使用
			因为a索引没有使用，所以这里 bc都没有用上索引效果
				- select * from myTest  where a>4 and b=7 and c=9;
			a用到了  b没有使用，c没有使用
				- select * from myTest  where a=3 order by b;
			a用到了索引，b在结果排序中也用到了索引的效果，a下面任意一段的b是排好序的
				- select * from myTest  where a=3 order by c;
			a用到了索引，但是这个地方c没有发挥排序效果，因为中间断点了，使用 explain 可以看到 filesort
				- select * from mytable where b=3 order by a;
			b没有用到索引，排序中a也没有发挥索引效果
	- 连接查询的常见问题
		- 凡是不符合WHERE子句中条件的记录都不会参与连接。只要我们在搜索条件中指定关于被驱动表相关列的值不为NULL，那么外连接中在被驱动表中找不到符合ON子句条件的驱动表记录也就被排除出最后的结果集了，也就是说：在这种情况下：外连接和内连接也就没有什么区别了（存在空值拒绝后，那么外连接以及内连接就可以相互装换）
	- select查询索引失效的原因
		- Order by对于复合索引排序要求子句后边列的顺序必须按照索引列的顺序给出，否则无法使用索引
		- 对索引列执行函数操作
		- 如果条件中有or，即使其中有条件带索引也不会使用（这也是为什么尽量少用or的原因）
		- 对于多列索引，不是使用的第一部分（第一个），则不会使用索引（为什么没有最左索引，就不会走索引这条路？因为索引是有序的，如果要走索引的话，必须要有序可寻，如果没有最左索引，直接跳过的话，则顺序无法确定，mysql无法判别该怎么搜索，只好全扫）
		- like查询是以%开头（前导模糊查询）
		- 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引
		- 如果mysql估计使用全表扫描要比使用索引快,则不使用索引（代价计算的原因）
	- 乐观锁存在失效的情况
		- 应用采用自己的策略管理主键ID。如，常见的取当前ID字段的最大值＋1作为新ID。
		- 版本号字段 version 默认值为 0 。
		- 用户A读取了某个记录准备修改它。该记录正好是ID最大的记录，且之前没被修改过，version 为默认值 0。
		- 在用户A读取完成后，用户B恰好删除了该记录。之后，用户C又插入了一个新记录。此时，阴差阳错的，新插入的记录的ID与用户A读取的记录的ID是一致的， 而版本号两者又都是默认值 0。
		- 用户A在用户C操作完成后，修改完成记录并保存。由于ID、version均可以匹配上，因此用户A成功保存。但是，却把用户C插入的记录覆盖掉了。
		- 乐观锁此时的失效，根本原因在于应用所使用的主键ID管理策略， 正好与乐观锁存在极小程度上的不兼容。
	- 数据库引擎（InnoDB）
		- 对于异常，InnoDB默认不会采取回滚操作，而对于死锁的情况会采取回滚操作
	- 读写分离的问题
		- 数据库主备切换
			- 基于位点执行主备切换
				- MASTER_LOG_FILE 和 MASTER_LOG_POS 表示，要从主库的 master_log_name 文件的 master_log_pos 这个位置的日志继续同步。而这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量
			- GTID（GTID=server_uuid:gno ）
				- server_uuid 是一个实例第一次启动时自动生成的，是一个全局唯一的值； gno 是一个整数，初始值是 1，每次提交事务的时候分配给这个事务，并加 1
				- 在基于 GTID 的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的
		- 从库可能无法读取到最新的主库信息（本质出现的原因是一写多读（不是读本库））
			- 强制走主库（针对某些对于数据实时性要求高的业务）
			- sleep方案
				- 仍旧有可能导致读到过期的数据信息
			- 判断主备无延迟方案
				- 对比 GTID 集合确保主备无延（配合 semi-sync）
				- 针对一主一从的场景适合，如果是多个从库，只要有一个从库返回ACK即可；如果查询请求落入了别的从库，则会导致过期读的产生
				- 如果在业务更新的高峰期，主库的位 点或者 GTID 集合更新很快，那么上面的两个位点等值判断就会一直不成立，很可能出现从库上迟迟无法响应查询请求的情况。
			- 等主库位点方案（可选方案，明天面试可能会问到）
				- 事务trx1更新完成后，马上执行SHOW MASTER STATUS，得到当前主库执行到的File和Position
				- 在该从库上先执行SELECT MASTER_POS_WAIT(File, Position, 1)
					- 若大于等于0，在从库执行查询语句
					- 否则返回主库查询
				- select master_pos_wait(file, pos[, timeout]); 参数file和pos指的是主库上的文件名和位置，返回正整数，表示从命令开始执行，到应用完file和pos，总共执行了多少事务
					- 如果在执行期间，从库的同步线程发生异常，返回NULL
					- 如果等待超过timeout秒，返回-1
					- 如果刚开始执行的时候，发现已经执行过这个位置，返回0
					- ![示例图](https://github.com/chuntaojun/Java_Note/blob/master/faq/image/6BDD2092-DC7A-F742-A2A3-9BC7DB61CE7E.png)
	- 为什么redo log buffer的内容不需要每次生成后都持久化到磁盘
		- 事务执行期间mysql发生异常重启，那么这部分日志就丢失了，但是由于redo log的两阶段提交（没有执行到commit阶段，binlog也未写完成，即事务未完成），如果此时事务并没有提交，那么日志丢失了也无所谓
	- 为何mysql的自增主键不是连续的
		- 自增主键的值在mysql8.0之前，是存储在内存当中的，如果说删除了数据，自增值是不会进行回滚操作的，自增值只针对数据的插入操作；并且，自增值会在mysql重启之后，自动读取表中的记录的最大ID值，进行加一操作然后在回存到内存当中
		- 对于自增列的一些要求
			- 必须是索引列，且必须是索引的第一列
		- 老版本的mysql对于自增值不会做持久化操作（记录到redo log中）
		- 自增的修改机制
			- 由于主键可能人为的插入，因此存在这种情况：某次主键插入的值是x，当前自增的值是y
				- 如果x < y，表的自增值保持不变
				- 如果x > y，表的自增值从y改为x，x作为当前新的自增值
			- 当插入数据时，自增值的更改是在真正执行数据插入之前；在数据插入出现冲突时，不会将自增值数据回滚
		- Insert … select为何要采用语句级别的锁（binlog_format=statement类型）
			- 当同时出现两个session执行插入动作时，binlog只有两种情况，要么先记录A，要么先记录B
			- binlog去从库执行或者恢复临时实例，假设先session B执行，那么此时的生成结果中，B的id都是连续的，此时，库发生了数据不一致的情况
			- 解决办法
				- 让原库的批量插入数据语句，固定生成连续的id值，因此自增锁的释放直到语句结束才会被执行的原因就是这个
				- 将binlog更改format格式为row，如实的记录插入数据的操作，到备库执行时，就需要依赖自增主键生成策略了
		- 自增id的申请策略
			- 下一次申请的数量是上一次申请数量的2倍，因此可能造成申请过多的自增id而导致没有用上，从而造成自增不连续
		- 自增主键的值取完该怎么办？
			- 如果是在表中定义自增主键，如果主键的值达到了上限，那么会出现插入数据错误（自增获取到的主键值一直为最大值）
			- 如果是由MySQL默认创建的主键值，则达到最大值后，下一次在获取主键值时变为0，重新开始一轮主键的获取，因此存在数据被覆盖的问题
	- 什么叫mysql的双“1”配置
		- 将sync_binlog和innodb_flush_log_at_trx_commit都设置成1，因此在提交一次事务时，需要刷两次磁盘，一次是redo log的prepare阶段，一次是binlog
		- 组提交机制
			- 日志逻辑序列号（LSN）
				- 单调递增，用来对应redo log的一个个写入点，每次写入长度为length的redo log，则lsn也加上length
				- LSN也会写入到Innodb的数据页中，确保数据页不会被多次执行redo log操作
	- MySQL在锁表时，怎么判断表里有没有记录被锁住（意向锁）
		- 行锁是行级别的，粒度比较小，好，那我要你在拿行锁之前，必须先拿一个假的表锁，表示你想去锁住表里的某一行或者多行记录，这样，MySQL判断表里有没有记录被锁定，就不需要遍历整张表了，它只需要看看，有没有人拿了这个假的表锁（意向锁）
	- MySQL大字段的优化
		- 前期概念：如果数据溢出，会将数据存储在溢出段中；InnoDB默认的块大小为16kb，由于B+树索引组织的特新，每一页的数据至少要两条数据，因此每行最大数据大小为8K；mysql在操作数据的时候，以page为单位，不管是更新，插入，删除一行数据，都需要将那行数据所在的page读到内存中，然后在进行操作，这样就存在一个命中率的问题，如果一个page中能够相对的存放足够多的行，那么命中率就会相对高一些，性能就会有提升；
		- 解决方法
			- 核心思想：让page中能够存储更多的行数据
			- innodb提供了barracuda文件格式，将大字段完全存放在溢出段中，数据段中只存放20个字节，这样就大大的减小了数据页的空间占用，使得一个数据页能够存放更多的数据行，也就提高了内存的命中率；如果对溢出段的数据进行压缩，那么在空间使用上也会大大的降低，具体的的压缩比率可以设置key_blok_size来实现。
			- 将主表拆分为一对一的两个关联表：xx_msg表由于将大字段单独放到另外一张表后，单行长度变的非常的小，page的行密度相比原来的表大很多，这样就能够缓存足够多的行，表上的多个select由于buffer pool的高命中率而受益；应用程序需要额外维护的是一张大字段的子表；
			- 覆盖索引：如果查询语句中，都是查询表中的小字段，由于老的方案需要全表或者根据主键来定位表中的数据，但是还是以page为单位进行操作，blob字段存在还是会导致buffer pool命中率的下降，如果通过覆盖索引来优化上面的两个查询，索引和原表结构分开，从访问密度较小的数据页改为访问密度很大的索引页，随机io转换为顺序io，同时内存命中率大大提升；额外的开销为数据库多维护一个索引的代价（为小字段创建二级索引）
	- MySQL大量数据插入的优化点
		- MySQL中插入一个记录需要的时间由下列因素组成
			-  连接：（3）
			- 发送查询给服务器：（2）
			- 分析查询：（2）
			- 插入记录：（1x记录大小）
			- 插入索引：（1x索引）
			- 关闭：（1）
		- 一条SQL语句插入多条数据：SQL执行效率高的主要原因是合并后日志量（MySQL的binlog和innodb的事务让日志）减少了，降低日志刷盘的数据量和频率，从而提高效率。通过合并SQL语句，同时也能减少SQL语句解析的次数，减少网络传输的IO（在进行数据合并在同一SQL中务必不能超过SQL长度限制，通过max_allowed_packet配置可以修改）
		- 在事务中进行插入处理：使用事务可以提高数据的插入效率，这是因为进行一个INSERT操作时，MySQL内部会建立一个事务，在事务内才进行真正插入处理操作。通过使用事务可以减少创建事务的消耗，所有插入都在执行后才进行提交操作（事务太大可能会影响执行的效率。MySQL有innodb_log_buffer_size配置项，超过这个值会把innodb的数据刷到磁盘中，这时，效率会有所下降。所以比较好的做法是，在数据达到这个这个值前进行事务提交）
		- 数据有序插入： 由于数据库插入时，需要维护索引数据，无序的记录会增大维护索引的成本。我们可以参照InnoDB使用的B+tree索引，如果每次插入记录都在索引的最后面，索引的定位效率很高，并且对索引调整较小；如果插入的记录在索引中间，需要B+tree进行分裂合并等处理，会消耗比较多计算资源，并且插入记录的索引定位效率会下降，数据量较大时会有频繁的磁盘操作

8. Netty
	- writeAndFlush之发送速率不匹配
		- 调用writeAndFlush并不代表消息已经发送到网络上，它仅仅是个异步的消息发送操作而已，调用writeAndFlush之后，Netty会执行一系列操作，最终将消息发送到网络上
		- 如何防止消息挤压的情况出现
			- 服务端在使用EventExecutor时设置消息积压的最大个数
			- 利用Netty的高低水位机制
				- 当发送队列待发送的字节数组达到高水位上限时，对应的 Channel 就变为不可写状态。由于高水位并不影响业务线程调用 write 方法并把消息加入到待发送队列中，因此，必须要在消息发送时对 Channel 的状态进行判断：当到达高水位时，Channel 的状态被设置为不可写，通过对 Channel 的可写状态进行判断来决定是否发送消息。
			- 造成发送队列积压消息的原因
				- 高并发情况下，单个消息报太大、错误的将消息长度字段设置或者编码成一个非常大的值、ChannelHandler执行的业务逻辑耗时较长且消息读取的速度又快，容易造成消息在EventExecutor积压、网络瓶颈（发送速率超过网路链路速率）、对端读取速度小于己方消息发送速度，导致TCP缓冲区快速挤满
			- 如果业务线程调用writeAndFlush()发送消息，会生成WriteAndFlushTask，交由IO线程处理，write操作将消息写入ChannelOutboundBuffer（这本质是一个无界的链表），flush操作将ChannelOutboundBuffer写入socket的发送缓冲区
		- writeAndFlush操作背后的真实数据流向
			- ![示例图](https://github.com/chuntaojun/Java_Note/blob/master/faq/image/20D6502D-E15D-9D4A-87EB-D96B412B10D5.png)
	- Netty的channel是无法进行序列化的
		- 每个channel对应了一个物理链接，如果序列化后在反序列化，是无法恢复连接的
		- 每个channel内部用一个channelmeatdata记录了对应的TCP参数信息

9. Spring
	- 为什么SpringBoot用户自定义的配置能够覆盖自动装配的Class
		- Spring Boot的设计是加载应用级配置，随后再考虑自动配置类
	- ServerRequest
		- InMemoryWebSessionStore
			- ession采用延迟过期处理，内部实现一个ExpireSessionChecker类，以及一个clock成员变量，在createWebSession、retriveSession方法中，主动去检查当前WebSession存储容器中存储的session是否有过期的，如果有则移除
		- WebSession被包括在了ServerExchange中
		- request和response如何与当前请求挂钩
			- 将request存放至线程的ThreadLocal中
	- SpringBoot是如何扫描注解的
		- 扫描实现的类：ClassPathScanningCandidateComponentProvider、ClassPathBeanDefinitionScanner
		- 具体扫描实现的方法：ClassPathBeanDefinitionScanner.Set<BeanDefinitionHolder> doScan(String... basePackages)
	- Spring Cloud的某一些实现注意点
		- Spring cloud discovery的服务自动注册
			- Spring cloud discovery的服务自动注册时机是在发布WebServerInitializedEvent事件后执行服务的自动注册
		- Spring cloud config的配置管理
			- 感知到外部化配置的变更这部分代码的操作是需要用户来完成的。Spring Cloud Config 只提供了具备外部化配置可动态刷新的能力，并不具备自动感知外部化配置发生变更的能力。如果你的配置是基于Mysql来实现的，那么在代码里面肯定要有能力感知到配置发生变化了，然后再显示的调用 ContextRefresher 的 refresh方法，从而完成外部化配置的动态刷新（只会刷新使用RefreshScope注解的Bean）
				- ![示例图](https://github.com/chuntaojun/Java_Note/blob/master/faq/image/3FCC31EF-8A1F-224C-B92B-1BCAB80E31BD.png)
	- Spring 加载流程
		- ![示例图](https://github.com/chuntaojun/Java_Note/blob/master/faq/image/25B90DA7-32A5-FF40-A7A4-CF97A635242D.png)

10. Mybatis
	- 开启二级缓存时，如何解决多表查询时缓存的脏数据问题
		- 二级缓存的使用需要对象可以被序列化（继承序列化接口）
		- 使用cache-ref标签，引用另一个namespace下的cache，能够解决这个错误（影响：缓存操作的粒度变粗，多个mapper namespace下的操作都会对缓存使用造成影响）
	- 延迟加载是如何实现的（DefaultResultSetHandler）
		- 源码
			- ![示例图](https://github.com/chuntaojun/Java_Note/blob/master/faq/image/C33DB8C9-956C-CE4C-B2C8-8C2D7D5D50A9.png)
		- 在遍历字段时，如果存在嵌套查询时，那么当前对象会被替换成一个代理对象，并将configuration对象传入，然后对代理对象的get方法进行拦截，当get方法被调用时，前去查询数据库
		- 创建源对象
			- ![示例图](https://github.com/chuntaojun/Java_Note/blob/master/faq/image/597E7F9F-CF4E-3A4D-A3E3-536177D04DCD.png)
	- Mapper接口是如何实现sql查询的
		- 如果是spring继承的话，则会在代理中开启SqlSession，不必自己负责SqlSession的获取、关闭操作
		- 重要的机制——动态代理（cglib或者javasist去实现，通过接口生成一个代理类）——> 创建MapperMethod代理类
		- MapperMethod方法里的execute方法将方法的参数进行 convertArgsToSqlCommandParam 操作
		- Executor的实现类BaseExecutor执行query的方法中，queryFromDatabase方法是真正的进行数据库访问操作；如果开启缓存的话，当前真正执行sql查询的操作会被放入缓存中：localCache.putObject(key, EXECUTION_PLACEHOLDER);其中缓存的管理是采用LRU最近最少使用算法，底层的实现依赖于java的LinkedHashMap（通过重写removeEldestEntry方法进行删除、双向链表的第一个有效节点（header后的那个节点）为最近最少使用的节点，这是用来支持LRU算法的、调整accessOrder参数为true）
			- ![示例图](https://github.com/chuntaojun/Java_Note/blob/master/faq/image/A845ABAF-49E7-7C4F-A382-1C42DE171887.png)
	- 缓存的处理
		- LruCache、BlockingCache、FifoCache

11. Raft协议常见问题
	- 如果选举时产生均票怎么解决
		- 加入随机等待时间机制
	- 如何避免非正常节点对选举的影响
		- 采取预投票机制，首先节点发起一次预投票（term + 1），根据预投票结果在确定自己是否可以发起正式的投票（term ++）
	- 哪些候选者值得选票
		- erm、logIndex
		- 参与投票 V 不会对下面两种候选者 C 投票：一种是 lastTermC < lastTermV；另一种是 (lastTermV == lastTermC) && (lastLogIndexV > lastLogIndexC)。
